{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ef4b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rules: \n",
      "\n",
      "S->[['A', 'k', 'O']]\n",
      "A->[['A', 'd'], ['a', 'B'], ['a', 'C']]\n",
      "C->[['c']]\n",
      "B->[['b', 'B', 'C'], ['r']]\n",
      "\n",
      "After elimination of left recursion:\n",
      "\n",
      "S->[['A', 'k', 'O']]\n",
      "A->[['a', 'B', \"A'\"], ['a', 'C', \"A'\"]]\n",
      "C->[['c']]\n",
      "B->[['b', 'B', 'C'], ['r']]\n",
      "A'->[['d', \"A'\"], ['#']]\n",
      "\n",
      "After left factoring:\n",
      "\n",
      "S->[['A', 'k', 'O']]\n",
      "A->[['a', \"A''\"]]\n",
      "A''->[['B', \"A'\"], ['C', \"A'\"]]\n",
      "C->[['c']]\n",
      "B->[['b', 'B', 'C'], ['r']]\n",
      "A'->[['d', \"A'\"], ['#']]\n",
      "\n",
      "Calculated firsts: \n",
      "first(S) => {'a'}\n",
      "first(A) => {'a'}\n",
      "first(A'') => {'b', 'r', 'c'}\n",
      "first(C) => {'c'}\n",
      "first(B) => {'b', 'r'}\n",
      "first(A') => {'d', '#'}\n",
      "\n",
      "Calculated follows: \n",
      "follow(S) => {'$'}\n",
      "follow(A) => {'k'}\n",
      "follow(A'') => {'k'}\n",
      "follow(C) => {'d', 'k', 'c'}\n",
      "follow(B) => {'d', 'k', 'c'}\n",
      "follow(A') => {'k'}\n",
      "\n",
      "Firsts and Follow Result table\n",
      "\n",
      "Non-T      FIRST                FOLLOW              \n",
      "S          {'a'}                {'$'}               \n",
      "A          {'a'}                {'k'}               \n",
      "A''        {'b', 'r', 'c'}      {'k'}               \n",
      "C          {'c'}                {'d', 'k', 'c'}     \n",
      "B          {'b', 'r'}           {'d', 'k', 'c'}     \n",
      "A'         {'d', '#'}           {'k'}               \n",
      "\n",
      "Generated parsing table:\n",
      "\n",
      "           k           O           d           a           c           b           r           $\n",
      "S                                         S->A k O                                                \n",
      "A                                         A->a A''                                                \n",
      "A''                                                    A''->C A'   A''->B A'   A''->B A'            \n",
      "C                                                         C->c                                    \n",
      "B                                                                 B->b B C        B->r            \n",
      "A'        A'->#                A'->d A'                                                            \n",
      "\n",
      "Validate String => a r k O\n",
      "\n",
      "              Buffer                Stack               Action\n",
      "           $ O k r a                  S $        T[S][a] = S->A k O\n",
      "           $ O k r a              A k O $        T[A][a] = A->a A''\n",
      "           $ O k r a          a A'' k O $            Matched:a\n",
      "             $ O k r            A'' k O $     T[A''][r] = A''->B A'\n",
      "             $ O k r           B A' k O $            T[B][r] = B->r\n",
      "             $ O k r           r A' k O $            Matched:r\n",
      "               $ O k             A' k O $          T[A'][k] = A'->#\n",
      "               $ O k                k O $            Matched:k\n",
      "                 $ O                  O $            Matched:O\n",
      "                   $                    $                Valid\n",
      "\n",
      "Valid String!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "def removeLeftRecursion(rulesDiction):\n",
    "    store = {}\n",
    "    # traverse over rules\n",
    "    for lhs in rulesDiction:\n",
    "        alphaRules = []\n",
    "        betaRules = []\n",
    "        allrhs = rulesDiction[lhs]\n",
    "        for subrhs in allrhs:\n",
    "            if subrhs[0] == lhs:\n",
    "                alphaRules.append(subrhs[1:])\n",
    "            else:\n",
    "                betaRules.append(subrhs)\n",
    "        if len(alphaRules) != 0:\n",
    "            lhs_ = lhs + \"'\"\n",
    "            while (lhs_ in rulesDiction.keys())                     or (lhs_ in store.keys()):\n",
    "                lhs_ += \"'\"\n",
    "            for b in range(0, len(betaRules)):\n",
    "                betaRules[b].append(lhs_)\n",
    "            rulesDiction[lhs] = betaRules\n",
    "            for a in range(0, len(alphaRules)):\n",
    "                alphaRules[a].append(lhs_)\n",
    "            alphaRules.append(['#'])\n",
    "            store[lhs_] = alphaRules\n",
    "    for left in store:\n",
    "        rulesDiction[left] = store[left]\n",
    "    return rulesDiction\n",
    " \n",
    " \n",
    "def LeftFactoring(rulesDiction):\n",
    "    newDict = {}\n",
    "    for lhs in rulesDiction:\n",
    "        allrhs = rulesDiction[lhs]\n",
    "        temp = dict()\n",
    "        for subrhs in allrhs:\n",
    "            if subrhs[0] not in list(temp.keys()):\n",
    "                temp[subrhs[0]] = [subrhs]\n",
    "            else:\n",
    "                temp[subrhs[0]].append(subrhs)\n",
    "        new_rule = []\n",
    "        tempo_dict = {}\n",
    "        for term_key in temp:\n",
    "            allStartingWithTermKey = temp[term_key]\n",
    "            if len(allStartingWithTermKey) > 1:\n",
    "                lhs_ = lhs + \"'\"\n",
    "                while (lhs_ in rulesDiction.keys())                         or (lhs_ in tempo_dict.keys()):\n",
    "                    lhs_ += \"'\"\n",
    "                new_rule.append([term_key, lhs_])\n",
    "                ex_rules = []\n",
    "                for g in temp[term_key]:\n",
    "                    ex_rules.append(g[1:])\n",
    "                tempo_dict[lhs_] = ex_rules\n",
    "            else:\n",
    "                new_rule.append(allStartingWithTermKey[0])\n",
    "        newDict[lhs] = new_rule\n",
    "        for key in tempo_dict:\n",
    "            newDict[key] = tempo_dict[key]\n",
    "    return newDict\n",
    " \n",
    " \n",
    "def first(rule):\n",
    "    global rules, nonterm_userdef,         term_userdef, diction, firsts\n",
    "    if len(rule) != 0 and (rule is not None):\n",
    "        if rule[0] in term_userdef:\n",
    "            return rule[0]\n",
    "        elif rule[0] == '#':\n",
    "            return '#'\n",
    "    if len(rule) != 0:\n",
    "        if rule[0] in list(diction.keys()):\n",
    "            fres = []\n",
    "            rhs_rules = diction[rule[0]]\n",
    "            for itr in rhs_rules:\n",
    "                indivRes = first(itr)\n",
    "                if type(indivRes) is list:\n",
    "                    for i in indivRes:\n",
    "                        fres.append(i)\n",
    "                else:\n",
    "                    fres.append(indivRes)\n",
    "            if '#' not in fres:\n",
    "                return fres\n",
    "            else:\n",
    "                newList = []\n",
    "                fres.remove('#')\n",
    "                if len(rule) > 1:\n",
    "                    ansNew = first(rule[1:])\n",
    "                    if ansNew != None:\n",
    "                        if type(ansNew) is list:\n",
    "                            newList = fres + ansNew\n",
    "                        else:\n",
    "                            newList = fres + [ansNew]\n",
    "                    else:\n",
    "                        newList = fres\n",
    "                    return newList\n",
    "                fres.append('#')\n",
    "                return fres\n",
    " \n",
    " \n",
    "def follow(nt):\n",
    "    global start_symbol, rules, nonterm_userdef,         term_userdef, diction, firsts, follows\n",
    "    solset = set()\n",
    "    if nt == start_symbol:\n",
    "        solset.add('$')\n",
    " \n",
    "    for curNT in diction:\n",
    "        rhs = diction[curNT]\n",
    "        for subrule in rhs:\n",
    "            if nt in subrule:\n",
    "                while nt in subrule:\n",
    "                    index_nt = subrule.index(nt)\n",
    "                    subrule = subrule[index_nt + 1:]\n",
    "                    if len(subrule) != 0:\n",
    "                        res = first(subrule)\n",
    "                        if '#' in res:\n",
    "                            newList = []\n",
    "                            res.remove('#')\n",
    "                            ansNew = follow(curNT)\n",
    "                            if ansNew != None:\n",
    "                                if type(ansNew) is list:\n",
    "                                    newList = res + ansNew\n",
    "                                else:\n",
    "                                    newList = res + [ansNew]\n",
    "                            else:\n",
    "                                newList = res\n",
    "                            res = newList\n",
    "                    else:\n",
    "                        if nt != curNT:\n",
    "                            res = follow(curNT)\n",
    "                    if res is not None:\n",
    "                        if type(res) is list:\n",
    "                            for g in res:\n",
    "                                solset.add(g)\n",
    "                        else:\n",
    "                            solset.add(res)\n",
    "    return list(solset)\n",
    " \n",
    " \n",
    "def computeAllFirsts():\n",
    "    global rules, nonterm_userdef,         term_userdef, diction, firsts\n",
    "    for rule in rules:\n",
    "        k = rule.split(\"->\")\n",
    "        k[0] = k[0].strip()\n",
    "        k[1] = k[1].strip()\n",
    "        rhs = k[1]\n",
    "        multirhs = rhs.split('|')\n",
    "        for i in range(len(multirhs)):\n",
    "            multirhs[i] = multirhs[i].strip()\n",
    "            multirhs[i] = multirhs[i].split()\n",
    "        diction[k[0]] = multirhs\n",
    " \n",
    "    print(f\"\\nRules: \\n\")\n",
    "    for y in diction:\n",
    "        print(f\"{y}->{diction[y]}\")\n",
    "    print(f\"\\nAfter elimination of left recursion:\\n\")\n",
    " \n",
    "    diction = removeLeftRecursion(diction)\n",
    "    for y in diction:\n",
    "        print(f\"{y}->{diction[y]}\")\n",
    "    print(\"\\nAfter left factoring:\\n\")\n",
    " \n",
    "    diction = LeftFactoring(diction)\n",
    "    for y in diction:\n",
    "        print(f\"{y}->{diction[y]}\")\n",
    "    for y in list(diction.keys()):\n",
    "        t = set()\n",
    "        for sub in diction.get(y):\n",
    "            res = first(sub)\n",
    "            if res != None:\n",
    "                if type(res) is list:\n",
    "                    for u in res:\n",
    "                        t.add(u)\n",
    "                else:\n",
    "                    t.add(res)\n",
    "        firsts[y] = t\n",
    " \n",
    "    print(\"\\nCalculated firsts: \")\n",
    "    key_list = list(firsts.keys())\n",
    "    index = 0\n",
    "    for gg in firsts:\n",
    "        print(f\"first({key_list[index]}) \"\n",
    "              f\"=> {firsts.get(gg)}\")\n",
    "        index += 1\n",
    " \n",
    " \n",
    "def computeAllFollows():\n",
    "    global start_symbol, rules, nonterm_userdef,        term_userdef, diction, firsts, follows\n",
    "    for NT in diction:\n",
    "        solset = set()\n",
    "        sol = follow(NT)\n",
    "        if sol is not None:\n",
    "            for g in sol:\n",
    "                solset.add(g)\n",
    "        follows[NT] = solset\n",
    " \n",
    "    print(\"\\nCalculated follows: \")\n",
    "    key_list = list(follows.keys())\n",
    "    index = 0\n",
    "    for gg in follows:\n",
    "        print(f\"follow({key_list[index]})\"\n",
    "              f\" => {follows[gg]}\")\n",
    "        index += 1\n",
    " \n",
    " \n",
    "def createParseTable():\n",
    "    import copy\n",
    "    global diction, firsts, follows, term_userdef\n",
    "    print(\"\\nFirsts and Follow Result table\\n\")\n",
    "    mx_len_first = 0\n",
    "    mx_len_fol = 0\n",
    "    for u in diction:\n",
    "        k1 = len(str(firsts[u]))\n",
    "        k2 = len(str(follows[u]))\n",
    "        if k1 > mx_len_first:\n",
    "            mx_len_first = k1\n",
    "        if k2 > mx_len_fol:\n",
    "            mx_len_fol = k2\n",
    " \n",
    "    print(f\"{{:<{10}}} \"\n",
    "          f\"{{:<{mx_len_first + 5}}} \"\n",
    "          f\"{{:<{mx_len_fol + 5}}}\"\n",
    "          .format(\"Non-T\", \"FIRST\", \"FOLLOW\"))\n",
    "    for u in diction:\n",
    "        print(f\"{{:<{10}}} \"\n",
    "              f\"{{:<{mx_len_first + 5}}} \"\n",
    "              f\"{{:<{mx_len_fol + 5}}}\"\n",
    "              .format(u, str(firsts[u]), str(follows[u])))\n",
    "    ntlist = list(diction.keys())\n",
    "    terminals = copy.deepcopy(term_userdef)\n",
    "    terminals.append('$')\n",
    " \n",
    "    mat = []\n",
    "    for x in diction:\n",
    "        row = []\n",
    "        for y in terminals:\n",
    "            row.append('')\n",
    "        mat.append(row)\n",
    " \n",
    "    \n",
    "    grammar_is_LL = True\n",
    " \n",
    "   \n",
    "    for lhs in diction:\n",
    "        rhs = diction[lhs]\n",
    "        for y in rhs:\n",
    "            res = first(y)\n",
    "            if '#' in res:\n",
    "                if type(res) == str:\n",
    "                    firstFollow = []\n",
    "                    fol_op = follows[lhs]\n",
    "                    if fol_op is str:\n",
    "                        firstFollow.append(fol_op)\n",
    "                    else:\n",
    "                        for u in fol_op:\n",
    "                            firstFollow.append(u)\n",
    "                    res = firstFollow\n",
    "                else:\n",
    "                    res.remove('#')\n",
    "                    res = list(res) +                          list(follows[lhs])\n",
    "            ttemp = []\n",
    "            if type(res) is str:\n",
    "                ttemp.append(res)\n",
    "                res = copy.deepcopy(ttemp)\n",
    "            for c in res:\n",
    "                xnt = ntlist.index(lhs)\n",
    "                yt = terminals.index(c)\n",
    "                if mat[xnt][yt] == '':\n",
    "                    mat[xnt][yt] = mat[xnt][yt]                                    + f\"{lhs}->{' '.join(y)}\"\n",
    "                else:\n",
    "                    if f\"{lhs}->{y}\" in mat[xnt][yt]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        grammar_is_LL = False\n",
    "                        mat[xnt][yt] = mat[xnt][yt]                                        + f\",{lhs}->{' '.join(y)}\"\n",
    " \n",
    "    print(\"\\nGenerated parsing table:\\n\")\n",
    "    frmt = \"{:>12}\" * len(terminals)\n",
    "    print(frmt.format(*terminals))\n",
    " \n",
    "    j = 0\n",
    "    for y in mat:\n",
    "        frmt1 = \"{:>12}\" * len(y)\n",
    "        print(f\"{ntlist[j]} {frmt1.format(*y)}\")\n",
    "        j += 1\n",
    " \n",
    "    return (mat, grammar_is_LL, terminals)\n",
    " \n",
    " \n",
    "def validateStringUsingStackBuffer(parsing_table, grammarll1,\n",
    "                                   table_term_list, input_string,\n",
    "                                   term_userdef,start_symbol):\n",
    " \n",
    "    print(f\"\\nValidate String => {input_string}\\n\")\n",
    "    if grammarll1 == False:\n",
    "        return f\"\\nInput String = \"                f\"\\\"{input_string}\\\"\\n\"                f\"Grammar is not LL(1)\"\n",
    " \n",
    "   \n",
    " \n",
    "    stack = [start_symbol, '$']\n",
    "    buffer = []\n",
    " \n",
    "  \n",
    "    input_string = input_string.split()\n",
    "    input_string.reverse()\n",
    "    buffer = ['$'] + input_string\n",
    " \n",
    "    print(\"{:>20} {:>20} {:>20}\".\n",
    "          format(\"Buffer\", \"Stack\",\"Action\"))\n",
    " \n",
    "    while True:\n",
    "        if stack == ['$'] and buffer == ['$']:\n",
    "            print(\"{:>20} {:>20} {:>20}\"\n",
    "                  .format(' '.join(buffer),\n",
    "                          ' '.join(stack),\n",
    "                          \"Valid\"))\n",
    "            return \"\\nValid String!\"\n",
    "        elif stack[0] not in term_userdef:\n",
    "            x = list(diction.keys()).index(stack[0])\n",
    "            y = table_term_list.index(buffer[-1])\n",
    "            if parsing_table[x][y] != '':\n",
    "                entry = parsing_table[x][y]\n",
    "                print(\"{:>20} {:>20} {:>25}\".\n",
    "                      format(' '.join(buffer),\n",
    "                             ' '.join(stack),\n",
    "                             f\"T[{stack[0]}][{buffer[-1]}] = {entry}\"))\n",
    "                lhs_rhs = entry.split(\"->\")\n",
    "                lhs_rhs[1] = lhs_rhs[1].replace('#', '').strip()\n",
    "                entryrhs = lhs_rhs[1].split()\n",
    "                stack = entryrhs + stack[1:]\n",
    "            else:\n",
    "                return f\"\\nInvalid String! No rule at \"                        f\"Table[{stack[0]}][{buffer[-1]}].\"\n",
    "        else:\n",
    "            if stack[0] == buffer[-1]:\n",
    "                print(\"{:>20} {:>20} {:>20}\"\n",
    "                      .format(' '.join(buffer),\n",
    "                              ' '.join(stack),\n",
    "                              f\"Matched:{stack[0]}\"))\n",
    "                buffer = buffer[:-1]\n",
    "                stack = stack[1:]\n",
    "            else:\n",
    "                return \"\\nInvalid String! \"                        \"Unmatched terminal symbols\"\n",
    " \n",
    "sample_input_string = None\n",
    "\n",
    "rules=[\"S -> A k O\",\n",
    "       \"A -> A d | a B | a C\",\n",
    "       \"C -> c\",\n",
    "       \"B -> b B C | r\"]\n",
    " \n",
    "nonterm_userdef=['A','B','C']\n",
    "term_userdef=['k','O','d','a','c','b','r']\n",
    "sample_input_string=\"a r k O\"\n",
    "\n",
    "diction = {}\n",
    "firsts = {}\n",
    "follows = {}\n",
    " \n",
    "\n",
    "computeAllFirsts()\n",
    "\n",
    "start_symbol = list(diction.keys())[0]\n",
    "\n",
    "computeAllFollows()\n",
    " \n",
    "(parsing_table, result, tabTerm) = createParseTable()\n",
    " \n",
    "\n",
    "if sample_input_string != None:\n",
    "    validity = validateStringUsingStackBuffer(parsing_table, result,\n",
    "                                              tabTerm, sample_input_string,\n",
    "                                              term_userdef,start_symbol)\n",
    "    print(validity)\n",
    "else:\n",
    "    print(\"\\nNo input String detected\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9009c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
