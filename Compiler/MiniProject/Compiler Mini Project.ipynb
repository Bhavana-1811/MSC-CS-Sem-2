{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57bc3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rules: \n",
      "\n",
      "S->[['A', 'k', 'O']]\n",
      "A->[['A', 'd'], ['a', 'B'], ['a', 'C']]\n",
      "C->[['c']]\n",
      "B->[['b', 'B', 'C'], ['r']]\n",
      "\n",
      "After elimination of left recursion:\n",
      "\n",
      "S->[['A', 'k', 'O']]\n",
      "A->[['a', 'B', \"A'\"], ['a', 'C', \"A'\"]]\n",
      "C->[['c']]\n",
      "B->[['b', 'B', 'C'], ['r']]\n",
      "A'->[['d', \"A'\"], ['#']]\n",
      "\n",
      "After left factoring:\n",
      "\n",
      "S->[['A', 'k', 'O']]\n",
      "A->[['a', \"A''\"]]\n",
      "A''->[['B', \"A'\"], ['C', \"A'\"]]\n",
      "C->[['c']]\n",
      "B->[['b', 'B', 'C'], ['r']]\n",
      "A'->[['d', \"A'\"], ['#']]\n",
      "\n",
      "Calculated firsts: \n",
      "first(S) => {'a'}\n",
      "first(A) => {'a'}\n",
      "first(A'') => {'b', 'c', 'r'}\n",
      "first(C) => {'c'}\n",
      "first(B) => {'b', 'r'}\n",
      "first(A') => {'#', 'd'}\n",
      "\n",
      "Calculated follows: \n",
      "follow(S) => {'$'}\n",
      "follow(A) => {'k'}\n",
      "follow(A'') => {'k'}\n",
      "follow(C) => {'k', 'c', 'd'}\n",
      "follow(B) => {'k', 'c', 'd'}\n",
      "follow(A') => {'k'}\n",
      "\n",
      "Firsts and Follow Result table\n",
      "\n",
      "Non-T      FIRST                FOLLOW              \n",
      "S          {'a'}                {'$'}               \n",
      "A          {'a'}                {'k'}               \n",
      "A''        {'b', 'c', 'r'}      {'k'}               \n",
      "C          {'c'}                {'k', 'c', 'd'}     \n",
      "B          {'b', 'r'}           {'k', 'c', 'd'}     \n",
      "A'         {'#', 'd'}           {'k'}               \n",
      "\n",
      "Generated parsing table:\n",
      "\n",
      "           k           O           d           a           c           b           r           $\n",
      "S                                         S->A k O                                                \n",
      "A                                         A->a A''                                                \n",
      "A''                                                    A''->C A'   A''->B A'   A''->B A'            \n",
      "C                                                         C->c                                    \n",
      "B                                                                 B->b B C        B->r            \n",
      "A'        A'->#                A'->d A'                                                            \n",
      "\n",
      "Validate String => a r k O\n",
      "\n",
      "              Buffer                Stack               Action\n",
      "           $ O k r a                  S $        T[S][a] = S->A k O\n",
      "           $ O k r a              A k O $        T[A][a] = A->a A''\n",
      "           $ O k r a          a A'' k O $            Matched:a\n",
      "             $ O k r            A'' k O $     T[A''][r] = A''->B A'\n",
      "             $ O k r           B A' k O $            T[B][r] = B->r\n",
      "             $ O k r           r A' k O $            Matched:r\n",
      "               $ O k             A' k O $          T[A'][k] = A'->#\n",
      "               $ O k                k O $            Matched:k\n",
      "                 $ O                  O $            Matched:O\n",
      "                   $                    $                Valid\n",
      "\n",
      "Valid String!\n"
     ]
    }
   ],
   "source": [
    "def removeLeftRecursion(rulesDiction):\n",
    "    # for rule: A->Aa|b\n",
    "    # result: A->bA',A'->aA'|#\n",
    " \n",
    "    # 'store' has new rules to be added\n",
    "    store = {}\n",
    "    # traverse over rules\n",
    "    for lhs in rulesDiction:\n",
    "        # alphaRules stores subrules with left-recursion\n",
    "        # betaRules stores subrules without left-recursion\n",
    "        alphaRules = []\n",
    "        betaRules = []\n",
    "        # get rhs for current lhs\n",
    "        allrhs = rulesDiction[lhs]\n",
    "        for subrhs in allrhs:\n",
    "            if subrhs[0] == lhs:\n",
    "                alphaRules.append(subrhs[1:])\n",
    "            else:\n",
    "                betaRules.append(subrhs)\n",
    "        # alpha and beta containing subrules are separated\n",
    "        # now form two new rules\n",
    "        if len(alphaRules) != 0:\n",
    "            # to generate new unique symbol\n",
    "            # add ' till unique not generated\n",
    "            lhs_ = lhs + \"'\"\n",
    "            while (lhs_ in rulesDiction.keys()) \\\n",
    "                    or (lhs_ in store.keys()):\n",
    "                lhs_ += \"'\"\n",
    "            # make beta rule\n",
    "            for b in range(0, len(betaRules)):\n",
    "                betaRules[b].append(lhs_)\n",
    "            rulesDiction[lhs] = betaRules\n",
    "            # make alpha rule\n",
    "            for a in range(0, len(alphaRules)):\n",
    "                alphaRules[a].append(lhs_)\n",
    "            alphaRules.append(['#'])\n",
    "            # store in temp dict, append to\n",
    "            # - rulesDiction at end of traversal\n",
    "            store[lhs_] = alphaRules\n",
    "    # add newly generated rules generated\n",
    "    # - after removing left recursion\n",
    "    for left in store:\n",
    "        rulesDiction[left] = store[left]\n",
    "    return rulesDiction\n",
    " \n",
    " \n",
    "def LeftFactoring(rulesDiction):\n",
    "    # for rule: A->aDF|aCV|k\n",
    "    # result: A->aA'|k, A'->DF|CV\n",
    " \n",
    "    # newDict stores newly generated\n",
    "    # - rules after left factoring\n",
    "    newDict = {}\n",
    "    # iterate over all rules of dictionary\n",
    "    for lhs in rulesDiction:\n",
    "        # get rhs for given lhs\n",
    "        allrhs = rulesDiction[lhs]\n",
    "        # temp dictionary helps detect left factoring\n",
    "        temp = dict()\n",
    "        for subrhs in allrhs:\n",
    "            if subrhs[0] not in list(temp.keys()):\n",
    "                temp[subrhs[0]] = [subrhs]\n",
    "            else:\n",
    "                temp[subrhs[0]].append(subrhs)\n",
    "        # if value list count for any key in temp is > 1,\n",
    "        # - it has left factoring\n",
    "        # new_rule stores new subrules for current LHS symbol\n",
    "        new_rule = []\n",
    "        # temp_dict stores new subrules for left factoring\n",
    "        tempo_dict = {}\n",
    "        for term_key in temp:\n",
    "            # get value from temp for term_key\n",
    "            allStartingWithTermKey = temp[term_key]\n",
    "            if len(allStartingWithTermKey) > 1:\n",
    "                # left factoring required\n",
    "                # to generate new unique symbol\n",
    "                # - add ' till unique not generated\n",
    "                lhs_ = lhs + \"'\"\n",
    "                while (lhs_ in rulesDiction.keys()) \\\n",
    "                        or (lhs_ in tempo_dict.keys()):\n",
    "                    lhs_ += \"'\"\n",
    "                # append the left factored result\n",
    "                new_rule.append([term_key, lhs_])\n",
    "                # add expanded rules to tempo_dict\n",
    "                ex_rules = []\n",
    "                for g in temp[term_key]:\n",
    "                    ex_rules.append(g[1:])\n",
    "                tempo_dict[lhs_] = ex_rules\n",
    "            else:\n",
    "                # no left factoring required\n",
    "                new_rule.append(allStartingWithTermKey[0])\n",
    "        # add original rule\n",
    "        newDict[lhs] = new_rule\n",
    "        # add newly generated rules after left factoring\n",
    "        for key in tempo_dict:\n",
    "            newDict[key] = tempo_dict[key]\n",
    "    return newDict\n",
    " \n",
    " \n",
    "# calculation of first\n",
    "# epsilon is denoted by '#' (semi-colon)\n",
    " \n",
    "# pass rule in first function\n",
    "def first(rule):\n",
    "    global rules, nonterm_userdef, \\\n",
    "        term_userdef, diction, firsts\n",
    "    # recursion base condition\n",
    "    # (for terminal or epsilon)\n",
    "    if len(rule) != 0 and (rule is not None):\n",
    "        if rule[0] in term_userdef:\n",
    "            return rule[0]\n",
    "        elif rule[0] == '#':\n",
    "            return '#'\n",
    " \n",
    "    # condition for Non-Terminals\n",
    "    if len(rule) != 0:\n",
    "        if rule[0] in list(diction.keys()):\n",
    "            # fres temporary list of result\n",
    "            fres = []\n",
    "            rhs_rules = diction[rule[0]]\n",
    "            # call first on each rule of RHS\n",
    "            # fetched (& take union)\n",
    "            for itr in rhs_rules:\n",
    "                indivRes = first(itr)\n",
    "                if type(indivRes) is list:\n",
    "                    for i in indivRes:\n",
    "                        fres.append(i)\n",
    "                else:\n",
    "                    fres.append(indivRes)\n",
    " \n",
    "            # if no epsilon in result\n",
    "            # - received return fres\n",
    "            if '#' not in fres:\n",
    "                return fres\n",
    "            else:\n",
    "                # apply epsilon\n",
    "                # rule => f(ABC)=f(A)-{e} U f(BC)\n",
    "                newList = []\n",
    "                fres.remove('#')\n",
    "                if len(rule) > 1:\n",
    "                    ansNew = first(rule[1:])\n",
    "                    if ansNew != None:\n",
    "                        if type(ansNew) is list:\n",
    "                            newList = fres + ansNew\n",
    "                        else:\n",
    "                            newList = fres + [ansNew]\n",
    "                    else:\n",
    "                        newList = fres\n",
    "                    return newList\n",
    "                # if result is not already returned\n",
    "                # - control reaches here\n",
    "                # lastly if eplison still persists\n",
    "                # - keep it in result of first\n",
    "                fres.append('#')\n",
    "                return fres\n",
    " \n",
    " \n",
    "# calculation of follow\n",
    "# use 'rules' list, and 'diction' dict from above\n",
    " \n",
    "# follow function input is the split result on\n",
    "# - Non-Terminal whose Follow we want to compute\n",
    "def follow(nt):\n",
    "    global start_symbol, rules, nonterm_userdef, \\\n",
    "        term_userdef, diction, firsts, follows\n",
    "    # for start symbol return $ (recursion base case)\n",
    " \n",
    "    solset = set()\n",
    "    if nt == start_symbol:\n",
    "        # return '$'\n",
    "        solset.add('$')\n",
    " \n",
    "    # check all occurrences\n",
    "    # solset - is result of computed 'follow' so far\n",
    " \n",
    "    # For input, check in all rules\n",
    "    for curNT in diction:\n",
    "        rhs = diction[curNT]\n",
    "        # go for all productions of NT\n",
    "        for subrule in rhs:\n",
    "            if nt in subrule:\n",
    "                # call for all occurrences on\n",
    "                # - non-terminal in subrule\n",
    "                while nt in subrule:\n",
    "                    index_nt = subrule.index(nt)\n",
    "                    subrule = subrule[index_nt + 1:]\n",
    "                    # empty condition - call follow on LHS\n",
    "                    if len(subrule) != 0:\n",
    "                        # compute first if symbols on\n",
    "                        # - RHS of target Non-Terminal exists\n",
    "                        res = first(subrule)\n",
    "                        # if epsilon in result apply rule\n",
    "                        # - (A->aBX)- follow of -\n",
    "                        # - follow(B)=(first(X)-{ep}) U follow(A)\n",
    "                        if '#' in res:\n",
    "                            newList = []\n",
    "                            res.remove('#')\n",
    "                            ansNew = follow(curNT)\n",
    "                            if ansNew != None:\n",
    "                                if type(ansNew) is list:\n",
    "                                    newList = res + ansNew\n",
    "                                else:\n",
    "                                    newList = res + [ansNew]\n",
    "                            else:\n",
    "                                newList = res\n",
    "                            res = newList\n",
    "                    else:\n",
    "                        # when nothing in RHS, go circular\n",
    "                        # - and take follow of LHS\n",
    "                        # only if (NT in LHS)!=curNT\n",
    "                        if nt != curNT:\n",
    "                            res = follow(curNT)\n",
    " \n",
    "                    # add follow result in set form\n",
    "                    if res is not None:\n",
    "                        if type(res) is list:\n",
    "                            for g in res:\n",
    "                                solset.add(g)\n",
    "                        else:\n",
    "                            solset.add(res)\n",
    "    return list(solset)\n",
    " \n",
    " \n",
    "def computeAllFirsts():\n",
    "    global rules, nonterm_userdef, \\\n",
    "        term_userdef, diction, firsts\n",
    "    for rule in rules:\n",
    "        k = rule.split(\"->\")\n",
    "        # remove un-necessary spaces\n",
    "        k[0] = k[0].strip()\n",
    "        k[1] = k[1].strip()\n",
    "        rhs = k[1]\n",
    "        multirhs = rhs.split('|')\n",
    "        # remove un-necessary spaces\n",
    "        for i in range(len(multirhs)):\n",
    "            multirhs[i] = multirhs[i].strip()\n",
    "            multirhs[i] = multirhs[i].split()\n",
    "        diction[k[0]] = multirhs\n",
    " \n",
    "    print(f\"\\nRules: \\n\")\n",
    "    for y in diction:\n",
    "        print(f\"{y}->{diction[y]}\")\n",
    "    print(f\"\\nAfter elimination of left recursion:\\n\")\n",
    " \n",
    "    diction = removeLeftRecursion(diction)\n",
    "    for y in diction:\n",
    "        print(f\"{y}->{diction[y]}\")\n",
    "    print(\"\\nAfter left factoring:\\n\")\n",
    " \n",
    "    diction = LeftFactoring(diction)\n",
    "    for y in diction:\n",
    "        print(f\"{y}->{diction[y]}\")\n",
    " \n",
    "    # calculate first for each rule\n",
    "    # - (call first() on all RHS)\n",
    "    for y in list(diction.keys()):\n",
    "        t = set()\n",
    "        for sub in diction.get(y):\n",
    "            res = first(sub)\n",
    "            if res != None:\n",
    "                if type(res) is list:\n",
    "                    for u in res:\n",
    "                        t.add(u)\n",
    "                else:\n",
    "                    t.add(res)\n",
    " \n",
    "        # save result in 'firsts' list\n",
    "        firsts[y] = t\n",
    " \n",
    "    print(\"\\nCalculated firsts: \")\n",
    "    key_list = list(firsts.keys())\n",
    "    index = 0\n",
    "    for gg in firsts:\n",
    "        print(f\"first({key_list[index]}) \"\n",
    "              f\"=> {firsts.get(gg)}\")\n",
    "        index += 1\n",
    " \n",
    " \n",
    "def computeAllFollows():\n",
    "    global start_symbol, rules, nonterm_userdef,\\\n",
    "        term_userdef, diction, firsts, follows\n",
    "    for NT in diction:\n",
    "        solset = set()\n",
    "        sol = follow(NT)\n",
    "        if sol is not None:\n",
    "            for g in sol:\n",
    "                solset.add(g)\n",
    "        follows[NT] = solset\n",
    " \n",
    "    print(\"\\nCalculated follows: \")\n",
    "    key_list = list(follows.keys())\n",
    "    index = 0\n",
    "    for gg in follows:\n",
    "        print(f\"follow({key_list[index]})\"\n",
    "              f\" => {follows[gg]}\")\n",
    "        index += 1\n",
    " \n",
    " \n",
    "# create parse table\n",
    "def createParseTable():\n",
    "    import copy\n",
    "    global diction, firsts, follows, term_userdef\n",
    "    print(\"\\nFirsts and Follow Result table\\n\")\n",
    " \n",
    "    # find space size\n",
    "    mx_len_first = 0\n",
    "    mx_len_fol = 0\n",
    "    for u in diction:\n",
    "        k1 = len(str(firsts[u]))\n",
    "        k2 = len(str(follows[u]))\n",
    "        if k1 > mx_len_first:\n",
    "            mx_len_first = k1\n",
    "        if k2 > mx_len_fol:\n",
    "            mx_len_fol = k2\n",
    " \n",
    "    print(f\"{{:<{10}}} \"\n",
    "          f\"{{:<{mx_len_first + 5}}} \"\n",
    "          f\"{{:<{mx_len_fol + 5}}}\"\n",
    "          .format(\"Non-T\", \"FIRST\", \"FOLLOW\"))\n",
    "    for u in diction:\n",
    "        print(f\"{{:<{10}}} \"\n",
    "              f\"{{:<{mx_len_first + 5}}} \"\n",
    "              f\"{{:<{mx_len_fol + 5}}}\"\n",
    "              .format(u, str(firsts[u]), str(follows[u])))\n",
    " \n",
    "    # create matrix of row(NT) x [col(T) + 1($)]\n",
    "    # create list of non-terminals\n",
    "    ntlist = list(diction.keys())\n",
    "    terminals = copy.deepcopy(term_userdef)\n",
    "    terminals.append('$')\n",
    " \n",
    "    # create the initial empty state of ,matrix\n",
    "    mat = []\n",
    "    for x in diction:\n",
    "        row = []\n",
    "        for y in terminals:\n",
    "            row.append('')\n",
    "        # of $ append one more col\n",
    "        mat.append(row)\n",
    " \n",
    "    # Classifying grammar as LL(1) or not LL(1)\n",
    "    grammar_is_LL = True\n",
    " \n",
    "    # rules implementation\n",
    "    for lhs in diction:\n",
    "        rhs = diction[lhs]\n",
    "        for y in rhs:\n",
    "            res = first(y)\n",
    "            # epsilon is present,\n",
    "            # - take union with follow\n",
    "            if '#' in res:\n",
    "                if type(res) == str:\n",
    "                    firstFollow = []\n",
    "                    fol_op = follows[lhs]\n",
    "                    if fol_op is str:\n",
    "                        firstFollow.append(fol_op)\n",
    "                    else:\n",
    "                        for u in fol_op:\n",
    "                            firstFollow.append(u)\n",
    "                    res = firstFollow\n",
    "                else:\n",
    "                    res.remove('#')\n",
    "                    res = list(res) +\\\n",
    "                          list(follows[lhs])\n",
    "            # add rules to table\n",
    "            ttemp = []\n",
    "            if type(res) is str:\n",
    "                ttemp.append(res)\n",
    "                res = copy.deepcopy(ttemp)\n",
    "            for c in res:\n",
    "                xnt = ntlist.index(lhs)\n",
    "                yt = terminals.index(c)\n",
    "                if mat[xnt][yt] == '':\n",
    "                    mat[xnt][yt] = mat[xnt][yt] \\\n",
    "                                   + f\"{lhs}->{' '.join(y)}\"\n",
    "                else:\n",
    "                    # if rule already present\n",
    "                    if f\"{lhs}->{y}\" in mat[xnt][yt]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        grammar_is_LL = False\n",
    "                        mat[xnt][yt] = mat[xnt][yt] \\\n",
    "                                       + f\",{lhs}->{' '.join(y)}\"\n",
    " \n",
    "    # final state of parse table\n",
    "    print(\"\\nGenerated parsing table:\\n\")\n",
    "    frmt = \"{:>12}\" * len(terminals)\n",
    "    print(frmt.format(*terminals))\n",
    " \n",
    "    j = 0\n",
    "    for y in mat:\n",
    "        frmt1 = \"{:>12}\" * len(y)\n",
    "        print(f\"{ntlist[j]} {frmt1.format(*y)}\")\n",
    "        j += 1\n",
    " \n",
    "    return (mat, grammar_is_LL, terminals)\n",
    " \n",
    " \n",
    "def validateStringUsingStackBuffer(parsing_table, grammarll1,\n",
    "                                   table_term_list, input_string,\n",
    "                                   term_userdef,start_symbol):\n",
    " \n",
    "    print(f\"\\nValidate String => {input_string}\\n\")\n",
    " \n",
    "    # for more than one entries\n",
    "    # - in one cell of parsing table\n",
    "    if grammarll1 == False:\n",
    "        return f\"\\nInput String = \" \\\n",
    "               f\"\\\"{input_string}\\\"\\n\" \\\n",
    "               f\"Grammar is not LL(1)\"\n",
    " \n",
    "    # implementing stack buffer\n",
    " \n",
    "    stack = [start_symbol, '$']\n",
    "    buffer = []\n",
    " \n",
    "    # reverse input string store in buffer\n",
    "    input_string = input_string.split()\n",
    "    input_string.reverse()\n",
    "    buffer = ['$'] + input_string\n",
    " \n",
    "    print(\"{:>20} {:>20} {:>20}\".\n",
    "          format(\"Buffer\", \"Stack\",\"Action\"))\n",
    " \n",
    "    while True:\n",
    "        # end loop if all symbols matched\n",
    "        if stack == ['$'] and buffer == ['$']:\n",
    "            print(\"{:>20} {:>20} {:>20}\"\n",
    "                  .format(' '.join(buffer),\n",
    "                          ' '.join(stack),\n",
    "                          \"Valid\"))\n",
    "            return \"\\nValid String!\"\n",
    "        elif stack[0] not in term_userdef:\n",
    "            # take font of buffer (y) and tos (x)\n",
    "            x = list(diction.keys()).index(stack[0])\n",
    "            y = table_term_list.index(buffer[-1])\n",
    "            if parsing_table[x][y] != '':\n",
    "                # format table entry received\n",
    "                entry = parsing_table[x][y]\n",
    "                print(\"{:>20} {:>20} {:>25}\".\n",
    "                      format(' '.join(buffer),\n",
    "                             ' '.join(stack),\n",
    "                             f\"T[{stack[0]}][{buffer[-1]}] = {entry}\"))\n",
    "                lhs_rhs = entry.split(\"->\")\n",
    "                lhs_rhs[1] = lhs_rhs[1].replace('#', '').strip()\n",
    "                entryrhs = lhs_rhs[1].split()\n",
    "                stack = entryrhs + stack[1:]\n",
    "            else:\n",
    "                return f\"\\nInvalid String! No rule at \" \\\n",
    "                       f\"Table[{stack[0]}][{buffer[-1]}].\"\n",
    "        else:\n",
    "            # stack top is Terminal\n",
    "            if stack[0] == buffer[-1]:\n",
    "                print(\"{:>20} {:>20} {:>20}\"\n",
    "                      .format(' '.join(buffer),\n",
    "                              ' '.join(stack),\n",
    "                              f\"Matched:{stack[0]}\"))\n",
    "                buffer = buffer[:-1]\n",
    "                stack = stack[1:]\n",
    "            else:\n",
    "                return \"\\nInvalid String! \" \\\n",
    "                       \"Unmatched terminal symbols\"\n",
    " \n",
    " \n",
    "# DRIVER CODE - MAIN\n",
    " \n",
    "# NOTE: To test any of the sample sets, uncomment ->\n",
    "# 'rules' list, 'nonterm_userdef' list, 'term_userdef' list\n",
    "# and for any String validation uncomment following line with\n",
    "# 'sample_input_String' variable.\n",
    " \n",
    "sample_input_string = None\n",
    " \n",
    "# sample set 1 (Result: Not LL(1))\n",
    "# rules=[\"A -> S B | B\",\n",
    "#        \"S -> a | B c | #\",\n",
    "#        \"B -> b | d\"]\n",
    "# nonterm_userdef=['A','S','B']\n",
    "# term_userdef=['a','c','b','d']\n",
    "# sample_input_string=\"b c b\"\n",
    " \n",
    "# sample set 2 (Result: LL(1))\n",
    "# rules=[\"S -> A | B C\",\n",
    "#        \"A -> a | b\",\n",
    "#        \"B -> p | #\",\n",
    "#        \"C -> c\"]\n",
    "# nonterm_userdef=['A','S','B','C']\n",
    "# term_userdef=['a','c','b','p']\n",
    "# sample_input_string=\"p c\"\n",
    " \n",
    "# sample set 3 (Result: LL(1))\n",
    "# rules=[\"S -> A B | C\",\n",
    "#        \"A -> a | b | #\",\n",
    "#        \"B-> p | #\",\n",
    "#        \"C -> c\"]\n",
    "# nonterm_userdef=['A','S','B','C']\n",
    "# term_userdef=['a','c','b','p']\n",
    "# sample_input_string=\"a c b\"\n",
    " \n",
    "# sample set 4 (Result: Not LL(1))\n",
    "# rules = [\"S -> A B C | C\",\n",
    "#          \"A -> a | b B | #\",\n",
    "#          \"B -> p | #\",\n",
    "#         \"C -> c\"]\n",
    "# nonterm_userdef=['A','S','B','C']\n",
    "# term_userdef=['a','c','b','p']\n",
    "# sample_input_string=\"b p p c\"\n",
    " \n",
    "# sample set 5 (With left recursion)\n",
    "# rules=[\"A -> B C c | g D B\",\n",
    "#        \"B -> b C D E | #\",\n",
    "#        \"C -> D a B | c a\",\n",
    "#        \"D -> # | d D\",\n",
    "#        \"E -> E a f | c\"\n",
    "#       ]\n",
    "# nonterm_userdef=['A','B','C','D','E']\n",
    "# term_userdef=[\"a\",\"b\",\"c\",\"d\",\"f\",\"g\"]\n",
    "# sample_input_string=\"b a c a c\"\n",
    " \n",
    "# sample set 6\n",
    "# rules=[\"E -> T E'\",\n",
    "#        \"E' -> + T E' | #\",\n",
    "#        \"T -> F T'\",\n",
    "#        \"T' -> * F T' | #\",\n",
    "#        \"F -> ( E ) | id\"\n",
    "# ]\n",
    "# nonterm_userdef=['E','E\\'','F','T','T\\'']\n",
    "# term_userdef=['id','+','*','(',')']\n",
    "# sample_input_string=\"id * * id\"\n",
    "# example string 1\n",
    "# sample_input_string=\"( id * id )\"\n",
    "# example string 2\n",
    "# sample_input_string=\"( id ) * id + id\"\n",
    " \n",
    "# sample set 7 (left factoring & recursion present)\n",
    "rules=[\"S -> A k O\",\n",
    "       \"A -> A d | a B | a C\",\n",
    "       \"C -> c\",\n",
    "       \"B -> b B C | r\"]\n",
    " \n",
    "nonterm_userdef=['A','B','C']\n",
    "term_userdef=['k','O','d','a','c','b','r']\n",
    "sample_input_string=\"a r k O\"\n",
    " \n",
    "# sample set 8 (Multiple char symbols T & NT)\n",
    "# rules = [\"S -> NP VP\",\n",
    "#          \"NP -> P | PN | D N\",\n",
    "#          \"VP -> V NP\",\n",
    "#          \"N -> championship | ball | toss\",\n",
    "#          \"V -> is | want | won | played\",\n",
    "#          \"P -> me | I | you\",\n",
    "#          \"PN -> India | Australia | Steve | John\",\n",
    "#          \"D -> the | a | an\"]\n",
    "#\n",
    "# nonterm_userdef = ['S', 'NP', 'VP', 'N', 'V', 'P', 'PN', 'D']\n",
    "# term_userdef = [\"championship\", \"ball\", \"toss\", \"is\", \"want\",\n",
    "#                 \"won\", \"played\", \"me\", \"I\", \"you\", \"India\",\n",
    "#                 \"Australia\",\"Steve\", \"John\", \"the\", \"a\", \"an\"]\n",
    "# sample_input_string = \"India won the championship\"\n",
    " \n",
    "# diction - store rules inputed\n",
    "# firsts - store computed firsts\n",
    "diction = {}\n",
    "firsts = {}\n",
    "follows = {}\n",
    " \n",
    "# computes all FIRSTs for all non terminals\n",
    "computeAllFirsts()\n",
    "# assuming first rule has start_symbol\n",
    "# start symbol can be modified in below line of code\n",
    "start_symbol = list(diction.keys())[0]\n",
    "# computes all FOLLOWs for all occurrences\n",
    "computeAllFollows()\n",
    "# generate formatted first and follow table\n",
    "# then generate parse table\n",
    " \n",
    "(parsing_table, result, tabTerm) = createParseTable()\n",
    " \n",
    "# validate string input using stack-buffer concept\n",
    "if sample_input_string != None:\n",
    "    validity = validateStringUsingStackBuffer(parsing_table, result,\n",
    "                                              tabTerm, sample_input_string,\n",
    "                                              term_userdef,start_symbol)\n",
    "    print(validity)\n",
    "else:\n",
    "    print(\"\\nNo input String detected\")\n",
    " \n",
    "# Author: Tanmay P. Bisen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e9751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
